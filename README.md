Worked on designing a Retrieval Augmented Generation (RAG) based conversational agent incorporating different Large Language Models (LLMs) like Llama-8B, Mistral-7B and OLMo-7B models for question-answering tasks about ECE graduate coursework at Georgia Institute of Technology. Created and curated our own dataset containing query-response pairs, which were then used to fine-tune the RAG-based LLMs using Quantized Low rank Adaptation (QLoRA) and Parameter-Efficient Fine-Tuning (PEFT). Achieved better performance of the RAG-based LLMs after fine-tuning to the curated dataset measured through text similarity metrics like BLEU and ROUGE scores.
